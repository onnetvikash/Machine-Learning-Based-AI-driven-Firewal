{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code in this notebook is entirely for making example plots to use in the technical background of the report  \n",
    "### This notebook doesn't have any relation to the overall firewall project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAFACAYAAACcMus4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c8eb2a79e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xmin, xmax = -7, 5\n",
    "n = 50\n",
    "np.random.seed(0)\n",
    "X = np.random.normal(size=n)\n",
    "y = (X > 0).astype(np.float)\n",
    "X[X >= 0] *= 4\n",
    "X[X >= 0] += 2\n",
    "X[X < 0] -= 2\n",
    "\n",
    "# plot separated\n",
    "f, axarr = plt.subplots(1,2, sharey=True)\n",
    "f.set_figheight(5)\n",
    "f.set_figwidth(12)\n",
    "\n",
    "'''\n",
    "Figure 0\n",
    "'''\n",
    "for t,marker,c in zip([0.0,1.0],\"ox\",\"gb\"):\n",
    "    # plot each class on its own to get different colored markers\n",
    "    axarr[0].scatter(X[y == t],\n",
    "                np.zeros(len(X[y==t])),\n",
    "                marker=marker,\n",
    "                c=c)\n",
    "    \n",
    "X_test = np.linspace(-7, 10, 300)\n",
    "\n",
    "axarr[0].set_ylabel('y')\n",
    "axarr[0].set_xlabel('X')\n",
    "axarr[0].set_xticks(range(-7, 10))\n",
    "axarr[0].set_yticks([0, 0.5, 1])\n",
    "axarr[0].set_ylim(-.25, 1.25)\n",
    "axarr[0].set_xlim(-7, 10)\n",
    "axarr[0].legend(('class 0', 'class 1'),\n",
    "           loc=\"lower right\", fontsize='small')\n",
    "\n",
    "\n",
    "'''\n",
    "Figure 1\n",
    "'''\n",
    "for t,marker,c in zip([0.0,1.0],\"ox\",\"gb\"):\n",
    "    # plot each class on its own to get different colored markers\n",
    "    axarr[1].scatter(X[y == t],\n",
    "                y[y==t],\n",
    "                marker=marker,\n",
    "                c=c)\n",
    "    \n",
    "#plt.scatter(X, y, c=y,color='black', zorder=20)\n",
    "X_test = np.linspace(-7, 10, 300)\n",
    "\n",
    "\n",
    "def model(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "loss = model(X_test)\n",
    "axarr[1].plot(X_test, loss, color='red', linewidth=3)\n",
    "\n",
    "\n",
    "axarr[1].set_ylabel('y')\n",
    "axarr[1].set_xlabel('X')\n",
    "axarr[1].set_xticks(range(-7, 10))\n",
    "axarr[1].set_yticks([0, 0.5, 1])\n",
    "axarr[1].set_ylim(-.25, 1.25)\n",
    "axarr[1].set_xlim(-7, 10)\n",
    "axarr[1].legend(('Logistic Regression Model', 'class 0', 'class 1'),\n",
    "           loc=\"lower right\", fontsize='small')\n",
    "plt.show()\n",
    "\n",
    "f.savefig('images/report_images/logistic.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine\n",
    "This is matlab code on how the image demonstrating linear vs RBF kernel was made (svm_kernel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "clear\n",
    "clc\n",
    "load('d2.mat');\n",
    "\n",
    "hold on\n",
    "gscatter(X(:,1),X(:,2),Y,'rb','x+',6);\n",
    "\n",
    "SVMstruct = svmtrain(X,Y,'boxconstraint',1,'autoscale',false,'kernel_function','RBF');\n",
    "        \n",
    "% Make a grid of values to classify the entire space\n",
    "x1_axis = linspace(min(X(:,1)), max(X(:,1)), 1000)';\n",
    "x2_axis = linspace(min(X(:,2)), max(X(:,2)), 1000)';\n",
    "\n",
    "[x1_space, x2_space] = meshgrid(x1_axis, x2_axis);\n",
    "\n",
    "for i = 1:size(x1_space, 2)\n",
    "   point_in_space = [x1_space(:, i), x2_space(:, i)];\n",
    "   class(:, i) = svmclassify(SVMstruct, point_in_space);\n",
    "end\n",
    "\n",
    "% Plot the SVM boundary\n",
    "hold on\n",
    "contour(x1_space, x2_space, class, [0 0], 'k');\n",
    "legend('-1','1','RBF boundary');\n",
    "xlabel('x1');\n",
    "ylabel('x2');\n",
    "title('Data points and decision boundary');\n",
    "hold off;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get2Grams(payload_obj):\n",
    "    '''Divides a string into 2-grams\n",
    "    \n",
    "    Example: input - payload: \"<script>\"\n",
    "             output- [\"<s\",\"sc\",\"cr\",\"ri\",\"ip\",\"pt\",\"t>\"]\n",
    "    '''\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-2):\n",
    "        ngrams.append(payload[i:i+2])\n",
    "    return ngrams\n",
    "\n",
    "classifier = pickle.load( open(\"data/tfidf_2grams_randomforest.p\", \"rb\"))\n",
    "\n",
    "def injection_test(inputs):\n",
    "    variables = inputs.split('&')\n",
    "    values = [ variable.split('=')[1] for variable in variables]\n",
    "    print(values)\n",
    "    return 'MALICIOUS' if classifier.predict(values).sum() > 0 else 'NOT_MALICIOUS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<rip cookie']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NOT_MALICIOUS'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_test('var1=<rip cookie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get1Grams(payload_obj):\n",
    "    '''Divides a string into 1-grams\n",
    "    \n",
    "    Example: input - payload: \"<script>\"\n",
    "             output- [\"<\",\"s\",\"c\",\"r\",\"i\",\"p\",\"t\",\">\"]\n",
    "    '''\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-1):\n",
    "        ngrams.append(payload[i:i+1])\n",
    "    return ngrams\n",
    "\n",
    "def get2Grams(payload_obj):\n",
    "    '''Divides a string into 2-grams\n",
    "    \n",
    "    Example: input - payload: \"<script>\"\n",
    "             output- [\"<s\",\"sc\",\"cr\",\"ri\",\"ip\",\"pt\",\"t>\"]\n",
    "    '''\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-2):\n",
    "        ngrams.append(payload[i:i+2])\n",
    "    return ngrams\n",
    "\n",
    "def get3Grams(payload_obj):\n",
    "    '''Divides a string into 3-grams\n",
    "    \n",
    "    Example: input - payload: \"<script>\"\n",
    "             output- [\"<sc\",\"scr\",\"cri\",\"rip\",\"ipt\",\"pt>\"]\n",
    "    '''\n",
    "    payload = str(payload_obj)\n",
    "    ngrams = []\n",
    "    for i in range(0,len(payload)-3):\n",
    "        ngrams.append(payload[i:i+3])\n",
    "    return ngrams\n",
    "\n",
    "classifierz = pickle.load( open(\"data/trained_classifiers.p\", \"rb\"))[['accuracy','sensitivity','specificity','auc','conf_matrix','params']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>auc</th>\n",
       "      <th>conf_matrix</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tfidf 1grams RandomForest</th>\n",
       "      <td>0.998324</td>\n",
       "      <td>0.992883</td>\n",
       "      <td>0.998856</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>[[20082, 23], [14, 1953]]</td>\n",
       "      <td>{'vect__min_df': 40, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 1grams RandomForest</th>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.989832</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.999426</td>\n",
       "      <td>[[20090, 15], [20, 1947]]</td>\n",
       "      <td>{'vect__min_df': 1, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 2grams RandomForest</th>\n",
       "      <td>0.998596</td>\n",
       "      <td>0.988307</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>[[20097, 8], [23, 1944]]</td>\n",
       "      <td>{'vect__min_df': 5, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 2grams RandomForest</th>\n",
       "      <td>0.998414</td>\n",
       "      <td>0.988307</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.99912</td>\n",
       "      <td>[[20093, 12], [23, 1944]]</td>\n",
       "      <td>{'vect__min_df': 1, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 2grams Logistic</th>\n",
       "      <td>0.998142</td>\n",
       "      <td>0.985257</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>[[20093, 12], [29, 1938]]</td>\n",
       "      <td>{'clf__C': 1000, 'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom SVM</th>\n",
       "      <td>0.99411</td>\n",
       "      <td>0.985257</td>\n",
       "      <td>0.994976</td>\n",
       "      <td>0.997742</td>\n",
       "      <td>[[20004, 101], [29, 1938]]</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 3grams MultinomialNB</th>\n",
       "      <td>0.993567</td>\n",
       "      <td>0.981698</td>\n",
       "      <td>0.994728</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>[[19999, 106], [36, 1931]]</td>\n",
       "      <td>{'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 1grams SVM</th>\n",
       "      <td>0.997327</td>\n",
       "      <td>0.980173</td>\n",
       "      <td>0.999005</td>\n",
       "      <td>0.997913</td>\n",
       "      <td>[[20085, 20], [39, 1928]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 2grams Logistic</th>\n",
       "      <td>0.997871</td>\n",
       "      <td>0.979664</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.998061</td>\n",
       "      <td>[[20098, 7], [40, 1927]]</td>\n",
       "      <td>{'clf__C': 10, 'vect__min_df': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 2grams SVM</th>\n",
       "      <td>0.997735</td>\n",
       "      <td>0.979156</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.99862</td>\n",
       "      <td>[[20096, 9], [41, 1926]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom RandomForest</th>\n",
       "      <td>0.996874</td>\n",
       "      <td>0.978139</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>0.998571</td>\n",
       "      <td>[[20079, 26], [43, 1924]]</td>\n",
       "      <td>{'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 2grams MultinomialNB</th>\n",
       "      <td>0.99411</td>\n",
       "      <td>0.978139</td>\n",
       "      <td>0.995673</td>\n",
       "      <td>0.989279</td>\n",
       "      <td>[[20018, 87], [43, 1924]]</td>\n",
       "      <td>{'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 3grams Logistic</th>\n",
       "      <td>0.997735</td>\n",
       "      <td>0.977631</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>[[20099, 6], [44, 1923]]</td>\n",
       "      <td>{'clf__C': 1000, 'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 3grams MultinomialNB</th>\n",
       "      <td>0.996058</td>\n",
       "      <td>0.976614</td>\n",
       "      <td>0.997961</td>\n",
       "      <td>0.999112</td>\n",
       "      <td>[[20064, 41], [46, 1921]]</td>\n",
       "      <td>{'vect__min_df': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 3grams RandomForest</th>\n",
       "      <td>0.997553</td>\n",
       "      <td>0.975089</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>[[20100, 5], [49, 1918]]</td>\n",
       "      <td>{'vect__min_df': 5, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 3grams RandomForest</th>\n",
       "      <td>0.997191</td>\n",
       "      <td>0.972039</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.99907</td>\n",
       "      <td>[[20098, 7], [55, 1912]]</td>\n",
       "      <td>{'vect__min_df': 5, 'clf__n_estimators': 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 3grams Logistic</th>\n",
       "      <td>0.997146</td>\n",
       "      <td>0.970513</td>\n",
       "      <td>0.999751</td>\n",
       "      <td>0.9981</td>\n",
       "      <td>[[20100, 5], [58, 1909]]</td>\n",
       "      <td>{'clf__C': 10, 'vect__min_df': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 3grams SVM</th>\n",
       "      <td>0.996693</td>\n",
       "      <td>0.968988</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>0.997568</td>\n",
       "      <td>[[20093, 12], [61, 1906]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 2grams MultinomialNB</th>\n",
       "      <td>0.995651</td>\n",
       "      <td>0.968988</td>\n",
       "      <td>0.998259</td>\n",
       "      <td>0.99798</td>\n",
       "      <td>[[20070, 35], [61, 1906]]</td>\n",
       "      <td>{'vect__min_df': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 2grams SVM</th>\n",
       "      <td>0.996693</td>\n",
       "      <td>0.967463</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>0.99909</td>\n",
       "      <td>[[20096, 9], [64, 1903]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 1grams Logistic</th>\n",
       "      <td>0.996104</td>\n",
       "      <td>0.967463</td>\n",
       "      <td>0.998906</td>\n",
       "      <td>0.998022</td>\n",
       "      <td>[[20083, 22], [64, 1903]]</td>\n",
       "      <td>{'clf__C': 1000, 'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 1grams Logistic</th>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.963396</td>\n",
       "      <td>0.999602</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>[[20097, 8], [72, 1895]]</td>\n",
       "      <td>{'clf__C': 10, 'vect__min_df': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count 1grams MultinomialNB</th>\n",
       "      <td>0.990939</td>\n",
       "      <td>0.962379</td>\n",
       "      <td>0.993733</td>\n",
       "      <td>0.976337</td>\n",
       "      <td>[[19979, 126], [74, 1893]]</td>\n",
       "      <td>{'vect__min_df': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom MLPClassifier</th>\n",
       "      <td>0.992796</td>\n",
       "      <td>0.954753</td>\n",
       "      <td>0.996518</td>\n",
       "      <td>0.997632</td>\n",
       "      <td>[[20035, 70], [89, 1878]]</td>\n",
       "      <td>{'learning_rate': 'invscaling', 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 1grams SVM</th>\n",
       "      <td>0.994246</td>\n",
       "      <td>0.949161</td>\n",
       "      <td>0.998657</td>\n",
       "      <td>0.996409</td>\n",
       "      <td>[[20078, 27], [100, 1867]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 3grams SVM</th>\n",
       "      <td>0.994971</td>\n",
       "      <td>0.947128</td>\n",
       "      <td>0.999652</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>[[20098, 7], [104, 1863]]</td>\n",
       "      <td>{'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom AdaBoostClassifier</th>\n",
       "      <td>0.98967</td>\n",
       "      <td>0.930351</td>\n",
       "      <td>0.995474</td>\n",
       "      <td>0.997814</td>\n",
       "      <td>[[20014, 91], [137, 1830]]</td>\n",
       "      <td>{'learning_rate': 1.0, 'n_estimators': 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tfidf 1grams MultinomialNB</th>\n",
       "      <td>0.991075</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.997314</td>\n",
       "      <td>0.99267</td>\n",
       "      <td>[[20051, 54], [143, 1824]]</td>\n",
       "      <td>{'vect__min_df': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom MultinomialNB</th>\n",
       "      <td>0.924339</td>\n",
       "      <td>0.916116</td>\n",
       "      <td>0.925143</td>\n",
       "      <td>0.971266</td>\n",
       "      <td>[[18600, 1505], [165, 1802]]</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom DecisionTree</th>\n",
       "      <td>0.9889</td>\n",
       "      <td>0.89578</td>\n",
       "      <td>0.99801</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>[[20065, 40], [205, 1762]]</td>\n",
       "      <td>{'min_samples_split': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom SGD</th>\n",
       "      <td>0.981606</td>\n",
       "      <td>0.877478</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.984595</td>\n",
       "      <td>[[19940, 165], [241, 1726]]</td>\n",
       "      <td>{'learning_rate': 'optimal'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom Logistic</th>\n",
       "      <td>0.98446</td>\n",
       "      <td>0.862227</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.990221</td>\n",
       "      <td>[[20033, 72], [271, 1696]]</td>\n",
       "      <td>{'C': 100}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            accuracy sensitivity specificity       auc  \\\n",
       "tfidf 1grams RandomForest   0.998324    0.992883    0.998856  0.999167   \n",
       "count 1grams RandomForest   0.998414    0.989832    0.999254  0.999426   \n",
       "tfidf 2grams RandomForest   0.998596    0.988307    0.999602  0.999375   \n",
       "count 2grams RandomForest   0.998414    0.988307    0.999403   0.99912   \n",
       "tfidf 2grams Logistic       0.998142    0.985257    0.999403  0.999489   \n",
       "custom SVM                   0.99411    0.985257    0.994976  0.997742   \n",
       "count 3grams MultinomialNB  0.993567    0.981698    0.994728  0.997707   \n",
       "count 1grams SVM            0.997327    0.980173    0.999005  0.997913   \n",
       "count 2grams Logistic       0.997871    0.979664    0.999652  0.998061   \n",
       "count 2grams SVM            0.997735    0.979156    0.999552   0.99862   \n",
       "custom RandomForest         0.996874    0.978139    0.998707  0.998571   \n",
       "count 2grams MultinomialNB   0.99411    0.978139    0.995673  0.989279   \n",
       "tfidf 3grams Logistic       0.997735    0.977631    0.999702  0.999575   \n",
       "tfidf 3grams MultinomialNB  0.996058    0.976614    0.997961  0.999112   \n",
       "tfidf 3grams RandomForest   0.997553    0.975089    0.999751  0.999082   \n",
       "count 3grams RandomForest   0.997191    0.972039    0.999652   0.99907   \n",
       "count 3grams Logistic       0.997146    0.970513    0.999751    0.9981   \n",
       "count 3grams SVM            0.996693    0.968988    0.999403  0.997568   \n",
       "tfidf 2grams MultinomialNB  0.995651    0.968988    0.998259   0.99798   \n",
       "tfidf 2grams SVM            0.996693    0.967463    0.999552   0.99909   \n",
       "tfidf 1grams Logistic       0.996104    0.967463    0.998906  0.998022   \n",
       "count 1grams Logistic       0.996375    0.963396    0.999602  0.996902   \n",
       "count 1grams MultinomialNB  0.990939    0.962379    0.993733  0.976337   \n",
       "custom MLPClassifier        0.992796    0.954753    0.996518  0.997632   \n",
       "tfidf 1grams SVM            0.994246    0.949161    0.998657  0.996409   \n",
       "tfidf 3grams SVM            0.994971    0.947128    0.999652  0.998131   \n",
       "custom AdaBoostClassifier    0.98967    0.930351    0.995474  0.997814   \n",
       "tfidf 1grams MultinomialNB  0.991075      0.9273    0.997314   0.99267   \n",
       "custom MultinomialNB        0.924339    0.916116    0.925143  0.971266   \n",
       "custom DecisionTree           0.9889     0.89578     0.99801  0.990906   \n",
       "custom SGD                  0.981606    0.877478    0.991793  0.984595   \n",
       "custom Logistic              0.98446    0.862227    0.996419  0.990221   \n",
       "\n",
       "                                             conf_matrix  \\\n",
       "tfidf 1grams RandomForest      [[20082, 23], [14, 1953]]   \n",
       "count 1grams RandomForest      [[20090, 15], [20, 1947]]   \n",
       "tfidf 2grams RandomForest       [[20097, 8], [23, 1944]]   \n",
       "count 2grams RandomForest      [[20093, 12], [23, 1944]]   \n",
       "tfidf 2grams Logistic          [[20093, 12], [29, 1938]]   \n",
       "custom SVM                    [[20004, 101], [29, 1938]]   \n",
       "count 3grams MultinomialNB    [[19999, 106], [36, 1931]]   \n",
       "count 1grams SVM               [[20085, 20], [39, 1928]]   \n",
       "count 2grams Logistic           [[20098, 7], [40, 1927]]   \n",
       "count 2grams SVM                [[20096, 9], [41, 1926]]   \n",
       "custom RandomForest            [[20079, 26], [43, 1924]]   \n",
       "count 2grams MultinomialNB     [[20018, 87], [43, 1924]]   \n",
       "tfidf 3grams Logistic           [[20099, 6], [44, 1923]]   \n",
       "tfidf 3grams MultinomialNB     [[20064, 41], [46, 1921]]   \n",
       "tfidf 3grams RandomForest       [[20100, 5], [49, 1918]]   \n",
       "count 3grams RandomForest       [[20098, 7], [55, 1912]]   \n",
       "count 3grams Logistic           [[20100, 5], [58, 1909]]   \n",
       "count 3grams SVM               [[20093, 12], [61, 1906]]   \n",
       "tfidf 2grams MultinomialNB     [[20070, 35], [61, 1906]]   \n",
       "tfidf 2grams SVM                [[20096, 9], [64, 1903]]   \n",
       "tfidf 1grams Logistic          [[20083, 22], [64, 1903]]   \n",
       "count 1grams Logistic           [[20097, 8], [72, 1895]]   \n",
       "count 1grams MultinomialNB    [[19979, 126], [74, 1893]]   \n",
       "custom MLPClassifier           [[20035, 70], [89, 1878]]   \n",
       "tfidf 1grams SVM              [[20078, 27], [100, 1867]]   \n",
       "tfidf 3grams SVM               [[20098, 7], [104, 1863]]   \n",
       "custom AdaBoostClassifier     [[20014, 91], [137, 1830]]   \n",
       "tfidf 1grams MultinomialNB    [[20051, 54], [143, 1824]]   \n",
       "custom MultinomialNB        [[18600, 1505], [165, 1802]]   \n",
       "custom DecisionTree           [[20065, 40], [205, 1762]]   \n",
       "custom SGD                   [[19940, 165], [241, 1726]]   \n",
       "custom Logistic               [[20033, 72], [271, 1696]]   \n",
       "\n",
       "                                                                       params  \n",
       "tfidf 1grams RandomForest       {'vect__min_df': 40, 'clf__n_estimators': 60}  \n",
       "count 1grams RandomForest        {'vect__min_df': 1, 'clf__n_estimators': 60}  \n",
       "tfidf 2grams RandomForest        {'vect__min_df': 5, 'clf__n_estimators': 60}  \n",
       "count 2grams RandomForest        {'vect__min_df': 1, 'clf__n_estimators': 60}  \n",
       "tfidf 2grams Logistic                     {'clf__C': 1000, 'vect__min_df': 1}  \n",
       "custom SVM                       {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}  \n",
       "count 3grams MultinomialNB                                {'vect__min_df': 1}  \n",
       "count 1grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "count 2grams Logistic                      {'clf__C': 10, 'vect__min_df': 20}  \n",
       "count 2grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "custom RandomForest                                      {'n_estimators': 40}  \n",
       "count 2grams MultinomialNB                                {'vect__min_df': 1}  \n",
       "tfidf 3grams Logistic                     {'clf__C': 1000, 'vect__min_df': 1}  \n",
       "tfidf 3grams MultinomialNB                                {'vect__min_df': 2}  \n",
       "tfidf 3grams RandomForest        {'vect__min_df': 5, 'clf__n_estimators': 60}  \n",
       "count 3grams RandomForest        {'vect__min_df': 5, 'clf__n_estimators': 60}  \n",
       "count 3grams Logistic                       {'clf__C': 10, 'vect__min_df': 2}  \n",
       "count 3grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "tfidf 2grams MultinomialNB                                {'vect__min_df': 2}  \n",
       "tfidf 2grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "tfidf 1grams Logistic                     {'clf__C': 1000, 'vect__min_df': 1}  \n",
       "count 1grams Logistic                      {'clf__C': 10, 'vect__min_df': 40}  \n",
       "count 1grams MultinomialNB                               {'vect__min_df': 20}  \n",
       "custom MLPClassifier        {'learning_rate': 'invscaling', 'learning_rate...  \n",
       "tfidf 1grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "tfidf 3grams SVM            {'clf__C': 100, 'clf__kernel': 'rbf', 'vect__m...  \n",
       "custom AdaBoostClassifier         {'learning_rate': 1.0, 'n_estimators': 100}  \n",
       "tfidf 1grams MultinomialNB                                {'vect__min_df': 1}  \n",
       "custom MultinomialNB                                           {'alpha': 1.0}  \n",
       "custom DecisionTree                                  {'min_samples_split': 2}  \n",
       "custom SGD                                       {'learning_rate': 'optimal'}  \n",
       "custom Logistic                                                    {'C': 100}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "display(classifierz)\n",
    "classifierz.to_csv('data/classifiers_result_table.csv',encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
